{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194bf460-01cb-457c-958e-5486375a68e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the correct file path for the medical df\n",
    "medical_file_path = \"medical_clean.csv\"\n",
    "# Read the medical df file with keep_default_na\n",
    "df = pd.read_csv(medical_file_path, keep_default_na=False, index_col=0)\n",
    "\n",
    "\n",
    "# Code to check for duplicates\n",
    "has_duplicates = df.duplicated().any()\n",
    "print(\"Duplicates present:\", has_duplicates)\n",
    "\n",
    "# Check for missing data\n",
    "missing_data = df.isnull().sum()\n",
    "\n",
    "# Display the missing data counts\n",
    "print(\"Missing data counts:\")\n",
    "print(missing_data)\n",
    "\n",
    "# Display data types\n",
    "df.info()\n",
    "\n",
    "# Visually inspect df\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "df.head(5)\n",
    "\n",
    "\n",
    "# Label encode binary categorical columns\n",
    "label_encoder = LabelEncoder()\n",
    "binary_columns = ['ReAdmis', 'HighBlood', 'Stroke', 'Overweight', 'Diabetes', 'Asthma']\n",
    "for col in binary_columns:\n",
    "    df[f'{col}_encoded'] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# Check for missing values after label encoding\n",
    "print(\"Missing values after label encoding:\")\n",
    "print(df[[f'{col}_encoded' for col in binary_columns]].isnull().sum())\n",
    "\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Encode categorical columns\n",
    "initial_admin_encoded = one_hot_encoder.fit_transform(df[['Initial_admin']])\n",
    "initial_admin_encoded_df = pd.DataFrame(initial_admin_encoded, columns=one_hot_encoder.get_feature_names_out(['Initial_admin']))\n",
    "\n",
    "services_encoded = one_hot_encoder.fit_transform(df[['Services']])\n",
    "services_encoded_df = pd.DataFrame(services_encoded, columns=one_hot_encoder.get_feature_names_out(['Services']))\n",
    "\n",
    "gender_encoded = one_hot_encoder.fit_transform(df[['Gender']])\n",
    "gender_encoded_df = pd.DataFrame(gender_encoded, columns=one_hot_encoder.get_feature_names_out(['Gender']))\n",
    "\n",
    "# Concatenate the encoded DataFrames\n",
    "df_combined = pd.concat([df, initial_admin_encoded_df, services_encoded_df, gender_encoded_df], axis=1)\n",
    "\n",
    "# Check for missing values after concatenation\n",
    "print(\"Missing values after concatenation:\")\n",
    "print(df_combined.isnull().sum())\n",
    "\n",
    "# Handle missing values (if any)\n",
    "# Fill missing values for numeric columns\n",
    "numeric_columns = df_combined.select_dtypes(include=['number']).columns\n",
    "df_combined[numeric_columns] = df_combined[numeric_columns].fillna(df_combined[numeric_columns].median())\n",
    "\n",
    "# Fill missing values for non-numeric columns\n",
    "non_numeric_columns = df_combined.select_dtypes(exclude=['number']).columns\n",
    "df_combined[non_numeric_columns] = df_combined[non_numeric_columns].fillna('Unknown')\n",
    "\n",
    "# Check for missing values after handling\n",
    "print(\"Missing values after handling:\")\n",
    "print(df_combined.isnull().sum())\n",
    "\n",
    "# Drop original categorical columns\n",
    "df_combined.drop(['ReAdmis', 'Gender', 'Initial_admin', 'HighBlood', 'Stroke', 'Overweight', 'Diabetes', 'Asthma', 'Services'], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "# Select columns for the decision tree model\n",
    "selected_columns = [\n",
    "    'Population', 'Children', 'Age', 'Income', 'VitD_levels', 'Doc_visits', 'Full_meals_eaten', 'vitD_supp', \n",
    "    'Initial_days', 'TotalCharge', 'Additional_charges'\n",
    "] + list(initial_admin_encoded_df.columns) + list(services_encoded_df.columns) + list(gender_encoded_df.columns) + [f'{col}_encoded' for col in binary_columns if col != 'ReAdmis']\n",
    "\n",
    "# Create new DataFrame for the decision tree\n",
    "tree_df = df_combined[selected_columns].assign(ReAdmis=df['ReAdmis_encoded'])\n",
    "\n",
    "# Check for missing values in the final DataFrame\n",
    "print(\"Missing values in the final DataFrame:\")\n",
    "print(tree_df.isnull().sum())\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(tree_df.head())\n",
    "\n",
    "# Save tree_df to a CSV file\n",
    "tree_df.to_csv(\"tree_df.csv\", index=False)\n",
    "print(\"tree_df has been saved to tree_df.csv.\")\n",
    "\n",
    "\n",
    "# Ensure there are no missing values in the target column\n",
    "tree_df = tree_df.dropna(subset=['ReAdmis'])\n",
    "\n",
    "# Separate features and target variable\n",
    "X = tree_df.drop('ReAdmis', axis=1)\n",
    "y = tree_df['ReAdmis']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the decision tree model\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Combine the training features and target into a single DataFrame\n",
    "train_tree_df = pd.concat([X_train, y_train], axis=1)\n",
    "test_tree_df = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# Save the train and test DataFrames to CSV files\n",
    "train_tree_df.to_csv(\"train_tree_df.csv\", index=False)\n",
    "test_tree_df.to_csv(\"test_tree_df.csv\", index=False)\n",
    "\n",
    "print(\"train_tree_df has been saved to 'train_tree_df.csv'.\")\n",
    "print(\"test_tree_df has been saved to 'test_tree_df.csv'.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Determine the number of nodes in the tree\n",
    "num_nodes = decision_tree.tree_.node_count\n",
    "print(f\"Number of nodes in the tree: {num_nodes}\")\n",
    "\n",
    "# Determine the depth of the tree\n",
    "tree_depth = decision_tree.get_depth()\n",
    "print(f\"Depth of the tree: {tree_depth}\")\n",
    "\n",
    "# Determine the number of leaves on the tree\n",
    "num_leaves = decision_tree.get_n_leaves()\n",
    "print(f\"Number of leaves in the tree: {num_leaves}\")\n",
    "\n",
    "\n",
    "\n",
    "# Determine feature importances\n",
    "feature_importances = decision_tree.feature_importances_\n",
    "for feature, importance in zip(X.columns, feature_importances):\n",
    "    print(f\"Feature: {feature}, Importance: {importance}\")\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(importance_df)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances in Decision Tree')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(\n",
    "    decision_tree, \n",
    "    feature_names=list(X.columns), \n",
    "    class_names=[\"Class 0\", \"Class 1\"], \n",
    "    filled=True, \n",
    "    rounded=True, \n",
    "    proportion=True, \n",
    "    precision=2\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=decision_tree, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_decision_tree = grid_search.best_estimator_\n",
    "\n",
    "# Train the pruned decision tree on the entire training set\n",
    "best_decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_decision_tree.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "\n",
    "\n",
    "# Visualize the pruned decision tree\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(\n",
    "    best_decision_tree, \n",
    "    feature_names=list(X.columns), \n",
    "    class_names=[\"Class 0\", \"Class 1\"], \n",
    "    filled=True, \n",
    "    rounded=True, \n",
    "    proportion=True, \n",
    "    precision=2\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
